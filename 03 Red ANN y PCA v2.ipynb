{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Carga de librerias </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# red neuronal\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# K-folds\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Grid Search \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Carga de datos </b>\n",
    "0 Standard,\n",
    "1 Poor,\n",
    "2 Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Num_Credit_Inquiries</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6292</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56617</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>35636</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>11333</td>\n",
       "      <td>312.494089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>6292</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24313</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>35636</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>10418</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-500</td>\n",
       "      <td>6292</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24313</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>35636</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>13844</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>6292</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24313</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>35636</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>25471</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>6292</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24313</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>35636</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>17527</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0   23        6292       19114.12            1824.843333                  3   \n",
       "1   23        6292       19114.12            1824.843333                  3   \n",
       "2 -500        6292       19114.12            1824.843333                  3   \n",
       "3   23        6292       19114.12            1824.843333                  3   \n",
       "4   23        6292       19114.12            1824.843333                  3   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
       "0                4              3            4                    3   \n",
       "1                4              3            4                   -1   \n",
       "2                4              3            4                    3   \n",
       "3                4              3            4                    5   \n",
       "4                4              3            4                    6   \n",
       "\n",
       "   Num_of_Delayed_Payment  ...  Num_Credit_Inquiries  Credit_Mix  \\\n",
       "0                     7.0  ...                   4.0       56617   \n",
       "1                    31.0  ...                   4.0       24313   \n",
       "2                     7.0  ...                   4.0       24313   \n",
       "3                     4.0  ...                   4.0       24313   \n",
       "4                    31.0  ...                   4.0       24313   \n",
       "\n",
       "   Outstanding_Debt  Credit_Utilization_Ratio  Payment_of_Min_Amount  \\\n",
       "0            809.98                 26.822620                  35636   \n",
       "1            809.98                 31.944960                  35636   \n",
       "2            809.98                 28.609352                  35636   \n",
       "3            809.98                 31.377862                  35636   \n",
       "4            809.98                 24.797347                  35636   \n",
       "\n",
       "   Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "0            49.574949                80.415295              11333   \n",
       "1            49.574949               118.280222              10418   \n",
       "2            49.574949                81.699521              13844   \n",
       "3            49.574949               199.458074              25471   \n",
       "4            49.574949                41.420153              17527   \n",
       "\n",
       "   Monthly_Balance  Credit_Score  \n",
       "0       312.494089             2  \n",
       "1       284.629162             2  \n",
       "2       331.209863             2  \n",
       "3       223.451310             2  \n",
       "4       341.489231             2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'dataset procesados/modelado.txt', sep=';')\n",
    "dict_cod = {'Standard':0, 'Poor':1, 'Good':2}\n",
    "dataset['Credit_Score'] = dataset['Credit_Score'].map(dict_cod)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Balance de datos </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    53111\n",
       "1    28965\n",
       "2    17814\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Credit_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGood = len(dataset[dataset['Credit_Score']==2])\n",
    "standard = dataset[dataset['Credit_Score']==0]\n",
    "poor = dataset[dataset['Credit_Score']==1]\n",
    "good = dataset[dataset['Credit_Score']==2]\n",
    "\n",
    "\n",
    "standard = standard.sample(2*nGood)\n",
    "dataset = pd.concat([standard, poor, good])\n",
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35628\n",
       "1    28965\n",
       "2    17814\n",
       "Name: Credit_Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Credit_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Verificación de Nulos </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Definición de datos para modelado </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, dataset.columns != 'Credit_Score']\n",
    "y = dataset.loc[:, 'Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> PCA </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999884737"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  1.  ,  0.  , -0.  , -0.  , -0.  ,  0.  , -0.  ,\n",
       "         0.  , -0.  ,  0.  , -0.  , -0.  ,  0.  , -0.  ,  0.  , -0.  ,\n",
       "        -0.  ,  0.  ],\n",
       "       [-0.  , -0.  ,  0.  , -0.02,  0.  , -0.  , -0.  , -0.  ,  0.  ,\n",
       "         0.  ,  0.  , -0.  ,  0.94, -0.01, -0.  ,  0.34, -0.  , -0.  ,\n",
       "         0.  , -0.  ],\n",
       "       [-0.  ,  0.  , -0.  ,  0.07, -0.  , -0.  , -0.  , -0.  , -0.  ,\n",
       "        -0.  , -0.  , -0.  ,  0.34, -0.05,  0.  , -0.94,  0.  ,  0.  ,\n",
       "        -0.02,  0.01],\n",
       "       [ 0.  ,  0.  , -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  , -0.  ,\n",
       "         0.  ,  0.  , -0.  , -0.  , -0.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  , -0.  ,  0.08, -0.  , -0.  ,  0.  , -0.  , -0.  ,\n",
       "        -0.  , -0.  , -0.  , -0.  , -0.01,  0.  ,  0.02, -0.  ,  0.  ,\n",
       "        -1.  ,  0.  ],\n",
       "       [-0.  ,  0.01, -0.  ,  0.99, -0.  , -0.  , -0.  , -0.  , -0.  ,\n",
       "         0.  , -0.  , -0.  , -0.01, -0.05,  0.  ,  0.07, -0.  ,  0.06,\n",
       "         0.08,  0.04],\n",
       "       [ 0.  ,  1.  , -0.  , -0.01,  0.  ,  0.  , -0.  ,  0.  , -0.  ,\n",
       "         0.  , -0.  ,  0.  , -0.  , -0.01, -0.  , -0.  , -0.  ,  0.01,\n",
       "         0.  , -0.  ],\n",
       "       [ 0.  , -0.01,  0.  , -0.06,  0.  , -0.  , -0.  , -0.  ,  0.  ,\n",
       "         0.  , -0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  ,  1.  ,\n",
       "        -0.  , -0.01],\n",
       "       [-0.  ,  0.01, -0.  ,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.01,\n",
       "         0.  ,  0.  ,  0.  ,  0.02,  1.  , -0.  , -0.04,  0.  ,  0.  ,\n",
       "        -0.  , -0.02],\n",
       "       [ 1.  , -0.  , -0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  , -0.  ,\n",
       "        -0.  ,  0.  , -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  , -0.  ,\n",
       "         0.  , -0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  ,  1.  , -0.  ,  0.  ,\n",
       "        -0.  , -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  , -0.  ,  0.  ,\n",
       "         0.  ,  0.  ],\n",
       "       [ 0.  , -0.  , -0.  , -0.  , -0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         1.  ,  0.  ,  0.01, -0.  , -0.  ,  0.  , -0.  , -0.  , -0.  ,\n",
       "        -0.  , -0.  ],\n",
       "       [ 0.  , -0.  , -0.  , -0.  , -0.  , -0.  , -0.  , -0.  , -0.  ,\n",
       "        -0.01, -0.  ,  1.  ,  0.  , -0.  ,  0.  , -0.  ,  0.  , -0.  ,\n",
       "        -0.  ,  0.01],\n",
       "       [ 0.  ,  0.  , -0.  , -0.04, -0.01,  0.  , -0.  , -0.  , -0.  ,\n",
       "         0.  , -0.  , -0.01, -0.  ,  0.02,  0.01,  0.  ,  0.  ,  0.  ,\n",
       "        -0.  ,  1.  ],\n",
       "       [ 0.  , -0.  ,  0.  ,  0.  , -0.01,  1.  ,  0.  ,  0.  ,  0.  ,\n",
       "        -0.01, -0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  ,  0.  ,  0.  ,\n",
       "        -0.  , -0.  ],\n",
       "       [-0.  , -0.  ,  0.  , -0.  ,  1.  ,  0.01,  0.  , -0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  ,  0.  , -0.  , -0.  ,\n",
       "        -0.  ,  0.01],\n",
       "       [ 0.  , -0.  , -0.  , -0.  ,  0.  , -0.  ,  0.  ,  1.  , -0.  ,\n",
       "        -0.  ,  0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  ,  0.  ,  0.  ,\n",
       "        -0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  ,  0.  ,  1.  ,\n",
       "        -0.  , -0.03, -0.  ,  0.  , -0.01,  0.  , -0.  ,  0.  ,  0.  ,\n",
       "        -0.  ,  0.  ],\n",
       "       [ 0.  , -0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  ,  0.  , -0.03,\n",
       "         0.  , -1.  , -0.  ,  0.  ,  0.  , -0.02,  0.  ,  0.  , -0.  ,\n",
       "        -0.  , -0.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pca.components_,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Red neuronal </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "# Tamaño de la muestra\n",
    "    'batch_size': [5,10], \n",
    "\n",
    "# Cantidad de epocas\n",
    "    'nb_epoch': [100,500],\n",
    "\n",
    "# Optimizador \n",
    "    'optimizer':['adam', 'SGD']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_grid_search_v1(optimizer):\n",
    "    clasificador = Sequential()\n",
    "    clasificador.add(Dense(input_dim=19, units=64, activation = 'softmax', kernel_initializer='uniform') )\n",
    "    clasificador.add(Dense(units=128, activation = 'softmax', kernel_initializer='uniform') )\n",
    "    clasificador.add(Dense(units=128, activation = 'softmax', kernel_initializer='uniform') )\n",
    "    clasificador.add(Dense(units=128, activation = 'softmax', kernel_initializer='uniform') )\n",
    "    clasificador.add(Dense(units=1, activation='softmax', kernel_initializer='uniform'))\n",
    "    clasificador.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-f1420de21d75>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  clasificador_grid_search = KerasClassifier(build_fn=red_grid_search_v1)\n"
     ]
    }
   ],
   "source": [
    "clasificador_grid_search = KerasClassifier(build_fn=red_grid_search_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out = GridSearchCV(estimator=clasificador_grid_search,\n",
    "                        param_grid=parametros,\n",
    "                        cv=20,\n",
    "                        scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.4544 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5310 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5298 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5287 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5288 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5239 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5308 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5000 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5294 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5297 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5290 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5298 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5290 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5272 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.4836 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.4732 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5284 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5296 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.4919 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5284 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5258 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5281 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5260 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 22s 2ms/step - loss: 0.5250 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5242 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 22s 2ms/step - loss: 0.5248 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5272 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 22s 2ms/step - loss: 0.5274 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 22s 2ms/step - loss: 0.5253 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5264 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5262 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5258 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5270 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5240 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5267 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 22s 2ms/step - loss: 0.5251 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5258 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5273 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5277 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5250 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 28s 2ms/step - loss: 0.5292 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5324 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 28s 2ms/step - loss: 0.5276 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5110 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5288 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 27s 2ms/step - loss: 0.5283 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5125 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.4961 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5281 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5295 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5279 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5307 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.5293 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.4463 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 26s 2ms/step - loss: 0.4673 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 28s 3ms/step - loss: 0.5187 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5292 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5308 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 28s 2ms/step - loss: 0.5302 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 3ms/step\n",
      "10960/10960 [==============================] - 37s 3ms/step - loss: 0.5292 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 31s 3ms/step - loss: 0.5253 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 33s 3ms/step - loss: 0.5278 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 31s 3ms/step - loss: 0.5270 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 29s 3ms/step - loss: 0.5258 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 29s 3ms/step - loss: 0.5256 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5248 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 25s 2ms/step - loss: 0.5275 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 24s 2ms/step - loss: 0.5281 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 30s 3ms/step - loss: 0.5254 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5262 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5259 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5270 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 21s 2ms/step - loss: 0.5262 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 19s 2ms/step - loss: 0.5242 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 19s 2ms/step - loss: 0.5261 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5246 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5260 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5268 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "10960/10960 [==============================] - 23s 2ms/step - loss: 0.5279 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "10960/10960 [==============================] - 20s 2ms/step - loss: 0.5248 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5330 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5344 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5337 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5318 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5329 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5327 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5351 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5350 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5166 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5331 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5330 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5355 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5340 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5325 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5337 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5313 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5325 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5337 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5342 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5338 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5291 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5315 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5299 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5282 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5280 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5282 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5308 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5307 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5284 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5297 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 10s 2ms/step - loss: 0.5297 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 10s 2ms/step - loss: 0.5303 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5296 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5280 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5296 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5271 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 3ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5289 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5304 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 3ms/step - loss: 0.5305 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5287 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5343 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 3ms/step - loss: 0.5349 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5131 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5309 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5326 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5321 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5290 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5341 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5326 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5346 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5320 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5331 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5344 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5317 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5341 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5307 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 16s 3ms/step - loss: 0.5326 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5343 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5345 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 15s 3ms/step - loss: 0.5325 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 17s 3ms/step - loss: 0.5287 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5313 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 3ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5302 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5281 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5289 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5284 - accuracy: 0.3498\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5309 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5306 - accuracy: 0.3487\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5285 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5302 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5296 - accuracy: 0.3500\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5307 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5293 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5273 - accuracy: 0.3492\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "5480/5480 [==============================] - 14s 2ms/step - loss: 0.5298 - accuracy: 0.3490\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5279 - accuracy: 0.3491\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5290 - accuracy: 0.3495\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 11s 2ms/step - loss: 0.5304 - accuracy: 0.3497\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 12s 2ms/step - loss: 0.5300 - accuracy: 0.3489\n",
      "91/91 [==============================] - 0s 1ms/step\n",
      "5480/5480 [==============================] - 13s 2ms/step - loss: 0.5289 - accuracy: 0.3494\n",
      "91/91 [==============================] - 0s 2ms/step\n",
      "11537/11537 [==============================] - 29s 2ms/step - loss: 0.5301 - accuracy: 0.3493\n"
     ]
    }
   ],
   "source": [
    "train_gs_out = grid_out.fit(X_train_pca, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 5, 'nb_epoch': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_out.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34931690892439493"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_out.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1803/1803 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     25006\n",
      "           1       0.35      1.00      0.52     20150\n",
      "           2       0.00      0.00      0.00     12528\n",
      "\n",
      "    accuracy                           0.35     57684\n",
      "   macro avg       0.12      0.33      0.17     57684\n",
      "weighted avg       0.12      0.35      0.18     57684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apatz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\apatz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\apatz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, grid_out.predict(X_train_pca) ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "721d5cc2a3432890c60d3b67ec7a8154d2297581962472e833721a025cc9dd92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
